{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster KAGGLE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on.\n",
    "\n",
    "First, login to Kaggle and go to the Titanic challenge to download train.csv and test.csv. Save them to the datasets/titanic directory.\n",
    "\n",
    "Next, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is already split into a training set and a test set. However, the test data does not contain the labels: your goal is to train the best model you can using the training data, then make your predictions on the test data and upload them to Kaggle to see your final score.\n",
    "\n",
    "Let's take a peek at the top few rows of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h5>The attributes have the following meaning:</h5>\n",
    "<ul>\n",
    "    <li><b>Survived:</b> that's the target, 0 means the passenger did not survive, while 1 means he/she survived.</li>\n",
    "    <li><b>Pclass:</b> passenger class.</li>\n",
    "    <li><b>Name, Sex, Age:</b> self-explanatory.</li>\n",
    "    <li><b>SibSp:</b> how many siblings & spouses of the passenger aboard the Titanic.</li>\n",
    "    <li><b>Parch:</b> how many children & parents of the passenger aboard the Titanic.</li>\n",
    "    <li><b>Ticket:</b> ticket id.</li>\n",
    "    <li><b>Fare:</b> price paid (in pounds).</li>\n",
    "    <li><b>Cabin:</b> passenger's cabin number.</li>\n",
    "    <li><b>Embarked:</b> where the passenger embarked the Titanic.</li>\n",
    "</ul>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Okay, the Age, Cabin and Embarked attributes are sometimes null (less than 891 non-null), especially the Cabin (77% are null). We will ignore the Cabin for now and focus on the rest. The Age attribute has about 19% null values, so we will need to decide what to do with them. Replacing null values with the median age seems reasonable.\n",
    "\n",
    "The Name and Ticket attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them.\n",
    "\n",
    "Let's take a look at the numerical attributes:\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<li>Yikes, only 38% Survived. :( Thats close enough to 40%, so accuracy will be a reasonable metric to evaluate our model.</li>\n",
    "<li>The mean Fare was £32.20, which does not seem so expensive (but it was probably a lot of money back then).</li>\n",
    "<li>The mean Age was less than 30 years old.</li>\n",
    "\n",
    "\n",
    "Let's check that the target is indeed 0 or 1:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a quick look at all the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "The Embarked attribute tells us where the passenger embarked: C=Cherbourg, Q=Queenstown, S=Southampton.\n",
    "\n",
    "Note: the code below uses a mix of Pipeline, FeatureUnion and a custom DataFrameSelector to preprocess some columns differently. Since Scikit-Learn 0.20, it is preferable to use a ColumnTransformer, like in the previous chapter.\n",
    "\n",
    "Now let's build our preprocessing pipelines. We will reuse the DataframeSelector we built in the previous chapter to select specific attributes from the DataFrame:\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "        #(\"select_numeric\", DataFrameSelector([\"AgeBucket\", \"RelativesOnboard\", \"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [28.    ,  1.    ,  2.    , 23.45  ],\n",
       "       [26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "We will also need an imputer for the string categorical columns (the regular SimpleImputer does not work on those):\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now we can build the pipeline for the categorical attributes:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's join the numerical and categorical pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have a nice preprocessing pipeline that takes the raw data and outputs numerical input features that we can feed to any Machine Learning model we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [38.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [26.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [28.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       [26.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [32.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget to get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a classifier. Let's start with an SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our model is trained, let's use it to make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "y_pred = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we could just build a CSV file with these predictions (respecting the format excepted by Kaggle), then upload it and hope for the best. But wait! We can do better than hope. Why don't we use cross-validation to have an idea of how good our model is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329588014981274"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, over 73% accuracy, clearly better than random chance, but it's not a great score. Looking at the leaderboard for the Titanic competition on Kaggle, you can see that you need to reach above 80% accuracy to be within the top 10% Kagglers. Some reached 100%, but since you can easily find the list of victims of the Titanic, it seems likely that there was little Machine Learning involved in their performance! ;-) So let's try to build a model that reaches 80% accuracy.\n",
    "\n",
    "Let's try a RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126466916354558"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forset_model=forest_clf.fit(X_train, y_train)\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better!\n",
    "\n",
    "Instead of just looking at the mean accuracy across the 10 cross-validation folds, let's plot all 10 scores for each model, along with a box plot highlighting the lower and upper quartiles, and \"whiskers\" showing the extent of the scores (thanks to Nevin Yilmaz for suggesting this visualization). Note that the boxplot() function detects outliers (called \"fliers\") and does not include them within the whiskers. Specifically, if the lower quartile is $Q_1$ and the upper quartile is $Q_3$, then the interquartile range $IQR = Q_3 - Q_1$ (this is the box's height), and any score lower than $Q_1 - 1.5 \\times IQR$ is a flier, and so is any score greater than $Q3 + 1.5 \\times IQR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, svm_scores, \".\")\n",
    "plt.plot([2]*10, forest_scores, \".\")\n",
    "plt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve this result further, you could:\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>Compare many more models and tune hyperparameters using cross validation and grid search,</li>\n",
    "<li>Do more feature engineering, for example:</li>\n",
    " <ul>  \n",
    "    <li>replace SibSp and Parch with their sum,</li>\n",
    "    <li>try to identify parts of names that correlate well with the Survived attribute (e.g. if the name contains \"Countess\", then survival seems more likely),</li>\n",
    "    </ul>\n",
    "\n",
    "    \n",
    "<li>try to convert numerical attributes to categorical attributes: for example, different age groups had very different survival rates (see below), so it may help to create an age bucket category and use it instead of the age. Similarly, it may be useful to have a special category for people traveling alone since only 30% of them survived (see below).</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()\n",
    "\n",
    "test_data[\"AgeBucket\"] = test_data[\"Age\"] // 15 * 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()\n",
    "\n",
    "\n",
    "test_data[\"RelativesOnboard\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\n",
    "# test_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>AgeBucket</th>\n",
       "      <th>RelativesOnboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  AgeBucket  \\\n",
       "0        0         A/5 21171   7.2500   NaN        S       15.0   \n",
       "1        0          PC 17599  71.2833   C85        C       30.0   \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S       15.0   \n",
       "3        0            113803  53.1000  C123        S       30.0   \n",
       "4        0            373450   8.0500   NaN        S       30.0   \n",
       "..     ...               ...      ...   ...      ...        ...   \n",
       "886      0            211536  13.0000   NaN        S       15.0   \n",
       "887      0            112053  30.0000   B42        S       15.0   \n",
       "888      2        W./C. 6607  23.4500   NaN        S        NaN   \n",
       "889      0            111369  30.0000  C148        C       15.0   \n",
       "890      0            370376   7.7500   NaN        Q       30.0   \n",
       "\n",
       "     RelativesOnboard  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   1  \n",
       "4                   0  \n",
       "..                ...  \n",
       "886                 0  \n",
       "887                 0  \n",
       "888                 3  \n",
       "889                 0  \n",
       "890                 0  \n",
       "\n",
       "[891 rows x 14 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.5,  0. ,  0. , ...,  0. ,  1. ,  0. ],\n",
       "       [47. ,  1. ,  0. , ...,  0. ,  0. ,  1. ],\n",
       "       [62. ,  0. ,  0. , ...,  0. ,  1. ,  0. ],\n",
       "       ...,\n",
       "       [38.5,  0. ,  0. , ...,  0. ,  0. ,  1. ],\n",
       "       [28. ,  0. ,  0. , ...,  0. ,  0. ,  1. ],\n",
       "       [28. ,  1. ,  1. , ...,  1. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        #(\"select_numeric\", DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "        (\"select_numeric\", DataFrameSelector([\"AgeBucket\", \"RelativesOnboard\", \"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_test=preprocess_pipeline.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [38.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [26.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [28.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       [26.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [32.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds=forset_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test_data['PassengerId'], 'Survived':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76666667, 0.82022472, 0.73033708, 0.83146067, 0.87640449,\n",
       "       0.85393258, 0.86516854, 0.74157303, 0.85393258, 0.85393258])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "# dtrain = lgb.Dataset(train[feature_cols], label=train['Stay'])\n",
    "# dvalid = lgb.Dataset(valid[feature_cols], label=valid['Stay'])\n",
    "\n",
    "#param = {'num_leaves': 64, 'objective': 'multiclass'}\n",
    "params = {}\n",
    "params['learning_rate'] = 0.05\n",
    "params['max_depth'] = 18\n",
    "params['n_estimators'] = 3000\n",
    "params['objective'] = 'binary'\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['subsample'] = 0.7\n",
    "params['random_state'] = 42\n",
    "params['colsample_bytree']=0.7\n",
    "params['min_data_in_leaf'] = 55\n",
    "params['reg_alpha'] = 1.7\n",
    "params['reg_lambda'] = 1.11\n",
    "params['class_weight']: {0: 0.62, 1: 0.38}\n",
    "\n",
    "\n",
    "\n",
    "clf = lgb.LGBMClassifier()\n",
    "\n",
    "\n",
    "lightgbm_scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "# clf.fit(train[feature_cols], train['Stay'], early_stopping_rounds=100, eval_set=[(valid[feature_cols], valid['Stay']),\n",
    "#         (test[feature_cols], test['Stay'])], eval_metric='multi_error', verbose=True)\n",
    "\n",
    "# eval_score = accuracy_score(test['Stay'], clf.predict(test[feature_cols]))\n",
    "\n",
    "# print('Eval ACC: {}'.format(eval_score))\n",
    "\n",
    "lightgbm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fraction = 0.20\n",
    "valid_size = int(len(X_train) * valid_fraction)\n",
    "\n",
    "train = X_train[:-2 * valid_size]\n",
    "valid = X_train[-2 * valid_size:-valid_size]\n",
    "test = X_train[-valid_size:]\n",
    "\n",
    "\n",
    "train_lb = y_train[:-2 * valid_size]\n",
    "valid_lb = y_train[-2 * valid_size:-valid_size]\n",
    "test_lb = y_train[-valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_error: 0.404494\tvalid_0's binary_logloss: 0.639516\tvalid_1's binary_error: 0.353933\tvalid_1's binary_logloss: 0.607577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_error: 0.382022\tvalid_0's binary_logloss: 0.610863\tvalid_1's binary_error: 0.325843\tvalid_1's binary_logloss: 0.571173\n",
      "[3]\tvalid_0's binary_error: 0.230337\tvalid_0's binary_logloss: 0.589127\tvalid_1's binary_error: 0.185393\tvalid_1's binary_logloss: 0.54245\n",
      "[4]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.570303\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.517847\n",
      "[5]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.555746\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.498767\n",
      "[6]\tvalid_0's binary_error: 0.230337\tvalid_0's binary_logloss: 0.540959\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.478768\n",
      "[7]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.532146\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.464705\n",
      "[8]\tvalid_0's binary_error: 0.230337\tvalid_0's binary_logloss: 0.522544\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.449483\n",
      "[9]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.515209\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.440699\n",
      "[10]\tvalid_0's binary_error: 0.230337\tvalid_0's binary_logloss: 0.508849\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.431009\n",
      "[11]\tvalid_0's binary_error: 0.230337\tvalid_0's binary_logloss: 0.502779\tvalid_1's binary_error: 0.168539\tvalid_1's binary_logloss: 0.42225\n",
      "[12]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.4983\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.414123\n",
      "[13]\tvalid_0's binary_error: 0.230337\tvalid_0's binary_logloss: 0.494897\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.408487\n",
      "[14]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.491799\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.401283\n",
      "[15]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.490291\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.397277\n",
      "[16]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.487412\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.39112\n",
      "[17]\tvalid_0's binary_error: 0.219101\tvalid_0's binary_logloss: 0.483984\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.38633\n",
      "[18]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.484489\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.383077\n",
      "[19]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.484853\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.379981\n",
      "[20]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.481562\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.376025\n",
      "[21]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.480141\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.374606\n",
      "[22]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.479477\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.372221\n",
      "[23]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.477299\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.368776\n",
      "[24]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.4747\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.364119\n",
      "[25]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.473329\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.361992\n",
      "[26]\tvalid_0's binary_error: 0.191011\tvalid_0's binary_logloss: 0.472594\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.358817\n",
      "[27]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.471466\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.355373\n",
      "[28]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.471292\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.350985\n",
      "[29]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.471198\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.348889\n",
      "[30]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.46955\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.345941\n",
      "[31]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.471516\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.342745\n",
      "[32]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.47224\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.34042\n",
      "[33]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.46963\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.337476\n",
      "[34]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.4716\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.338544\n",
      "[35]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.470888\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.338327\n",
      "[36]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.471116\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.338255\n",
      "[37]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.470328\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.337948\n",
      "[38]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.472184\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.339053\n",
      "[39]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.471893\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.336997\n",
      "[40]\tvalid_0's binary_error: 0.213483\tvalid_0's binary_logloss: 0.471614\tvalid_1's binary_error: 0.146067\tvalid_1's binary_logloss: 0.338383\n",
      "[41]\tvalid_0's binary_error: 0.213483\tvalid_0's binary_logloss: 0.473134\tvalid_1's binary_error: 0.146067\tvalid_1's binary_logloss: 0.336745\n",
      "[42]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.471409\tvalid_1's binary_error: 0.146067\tvalid_1's binary_logloss: 0.33689\n",
      "[43]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.473427\tvalid_1's binary_error: 0.146067\tvalid_1's binary_logloss: 0.337269\n",
      "[44]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.4716\tvalid_1's binary_error: 0.146067\tvalid_1's binary_logloss: 0.336445\n",
      "[45]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.471603\tvalid_1's binary_error: 0.146067\tvalid_1's binary_logloss: 0.337174\n",
      "[46]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.474713\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.337922\n",
      "[47]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.475631\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.337644\n",
      "[48]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.477658\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.338155\n",
      "[49]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.47535\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.339226\n",
      "[50]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.475182\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340175\n",
      "[51]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.475834\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.33998\n",
      "[52]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.477594\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339131\n",
      "[53]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.475138\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.341274\n",
      "[54]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.474621\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340069\n",
      "[55]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.474526\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.342333\n",
      "[56]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.477268\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.340361\n",
      "[57]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.476711\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.33836\n",
      "[58]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.478773\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338618\n",
      "[59]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.475728\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339519\n",
      "[60]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.47506\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339198\n",
      "[61]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.477488\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338342\n",
      "[62]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.477215\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338832\n",
      "[63]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.475449\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340299\n",
      "[64]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.475571\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.34017\n",
      "[65]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.477583\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.340478\n",
      "[66]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.478525\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340652\n",
      "[67]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.477398\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339578\n",
      "[68]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.477911\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340279\n",
      "[69]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.479434\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340738\n",
      "[70]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.480101\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340843\n",
      "[71]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.480261\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.341406\n",
      "[72]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.479514\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.341982\n",
      "[73]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.480738\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.33954\n",
      "[74]\tvalid_0's binary_error: 0.196629\tvalid_0's binary_logloss: 0.483892\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338949\n",
      "[75]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.484309\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339111\n",
      "[76]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.485162\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338977\n",
      "[77]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.487169\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339189\n",
      "[78]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.488804\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.339231\n",
      "[79]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.488007\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338026\n",
      "[80]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.490313\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.338443\n",
      "[81]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.491164\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.340373\n",
      "[82]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.491929\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.341709\n",
      "[83]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.497511\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.342127\n",
      "[84]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.496519\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.344396\n",
      "[85]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.497044\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.344332\n",
      "[86]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.499817\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.345228\n",
      "[87]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.498885\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.344972\n",
      "[88]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.497742\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.347582\n",
      "[89]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.499664\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.348852\n",
      "[90]\tvalid_0's binary_error: 0.202247\tvalid_0's binary_logloss: 0.501467\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.348832\n",
      "[91]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.50139\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.347796\n",
      "[92]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.502628\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.347802\n",
      "[93]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.50084\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.350443\n",
      "[94]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.501477\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.350626\n",
      "[95]\tvalid_0's binary_error: 0.207865\tvalid_0's binary_logloss: 0.500967\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.350319\n",
      "[96]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.502358\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.350635\n",
      "[97]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.503191\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.350099\n",
      "[98]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.505525\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.350183\n",
      "[99]\tvalid_0's binary_error: 0.219101\tvalid_0's binary_logloss: 0.505209\tvalid_1's binary_error: 0.129213\tvalid_1's binary_logloss: 0.35136\n",
      "[100]\tvalid_0's binary_error: 0.224719\tvalid_0's binary_logloss: 0.505799\tvalid_1's binary_error: 0.134831\tvalid_1's binary_logloss: 0.351859\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[26]\tvalid_0's binary_error: 0.191011\tvalid_0's binary_logloss: 0.472594\tvalid_1's binary_error: 0.140449\tvalid_1's binary_logloss: 0.358817\n",
      "Eval ACC: 0.8595505617977528\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train, train_lb, early_stopping_rounds=100, eval_set=[(valid, valid_lb),\n",
    "        (test, test_lb)], eval_metric='multi_error', verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "eval_score = accuracy_score(test_lb, clf.predict(test))\n",
    "\n",
    "print('Eval ACC: {}'.format(eval_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 18, 'n_estimators': 26, 'objective': 'binary', 'boosting_type': 'gbdt', 'subsample': 0.7, 'random_state': 42, 'colsample_bytree': 0.7, 'min_data_in_leaf': 55, 'reg_alpha': 1.7, 'reg_lambda': 1.11}\n",
      "ACC: 0.8092031425364759\n"
     ]
    }
   ],
   "source": [
    "best_iter = clf.best_iteration_\n",
    "params['n_estimators'] = best_iter\n",
    "print(params)\n",
    "\n",
    "\n",
    "clf = lgb.LGBMClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_metric='multi_error', verbose=False)\n",
    "\n",
    "# eval_score_auc = roc_auc_score(df_train[label_col], clf.predict(df_train[feature_cols]))\n",
    "eval_score_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "\n",
    "print('ACC: {}'.format(eval_score_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test_data['PassengerId'], 'Survived':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-98b5ea3dd301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#predictions_3 = my_model_3.predict(X_valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0meval_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_lb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_model_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Eval ACC: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 90\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "my_model_3 = XGBRegressor(n_estimators=1000, learning_rate=0.15)\n",
    "\n",
    "# Fit the model\n",
    "my_model_3.fit(train, train_lb,\n",
    "             early_stopping_rounds=5,\n",
    "               eval_set=[(valid, valid_lb),\n",
    "        (test, test_lb)],\n",
    "             verbose=False) # Your code here\n",
    "\n",
    "# Get predictions\n",
    "#predictions_3 = my_model_3.predict(X_valid)\n",
    "\n",
    "eval_score = accuracy_score(test_lb, my_model_3.predict(test))\n",
    "\n",
    "print('Eval ACC: {}'.format(eval_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
